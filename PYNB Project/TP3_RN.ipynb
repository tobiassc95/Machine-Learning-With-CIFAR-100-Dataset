{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8916c7c7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-01T13:27:24.688122Z",
     "iopub.status.busy": "2021-12-01T13:27:24.686613Z",
     "iopub.status.idle": "2021-12-01T13:27:24.697847Z",
     "shell.execute_reply": "2021-12-01T13:27:24.698451Z",
     "shell.execute_reply.started": "2021-12-01T12:39:40.731314Z"
    },
    "papermill": {
     "duration": 0.036096,
     "end_time": "2021-12-01T13:27:24.698721",
     "exception": false,
     "start_time": "2021-12-01T13:27:24.662625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cnn-itba-2021-q2/y_train.npy\n",
      "/kaggle/input/cnn-itba-2021-q2/X_test.npy\n",
      "/kaggle/input/cnn-itba-2021-q2/X_train.npy\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e95a12",
   "metadata": {
    "papermill": {
     "duration": 0.016773,
     "end_time": "2021-12-01T13:27:24.735310",
     "exception": false,
     "start_time": "2021-12-01T13:27:24.718537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Redes Neuronales 2021\n",
    "\n",
    "Integrantes de grupo:\n",
    "\n",
    "Müller, Malena\n",
    "\n",
    "Scala, Tobías \n",
    "# TP3: Convolutional Neural Network (CNN) & Transfer Learning\n",
    "\n",
    "El trabajo práctico consiste en la predicción de imagenes. El dataset utilizado es el CIFAR-100, el cual consiste de 60 mil imagenes (10 mil para test y 50 mil para train) con una variedad de 100 clases.Las imagenes tienen una resolución de 32x32 píxeles. Los 2 objetivos principales del presente TP son: el diseño de un modelo CNN y transfer learning con Imagenet. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea393a",
   "metadata": {
    "papermill": {
     "duration": 0.016916,
     "end_time": "2021-12-01T13:27:24.769240",
     "exception": false,
     "start_time": "2021-12-01T13:27:24.752324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Se obtiene el data set.\n",
    "Se obtiene el dataset presente en Kaggle, el cual es el CIFAR-100. Se normalizan los píxeles dividiendo por 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d9575a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T13:27:24.807727Z",
     "iopub.status.busy": "2021-12-01T13:27:24.807225Z",
     "iopub.status.idle": "2021-12-01T13:27:29.103061Z",
     "shell.execute_reply": "2021-12-01T13:27:29.102406Z",
     "shell.execute_reply.started": "2021-12-01T12:39:40.746118Z"
    },
    "papermill": {
     "duration": 4.317001,
     "end_time": "2021-12-01T13:27:29.103216",
     "exception": false,
     "start_time": "2021-12-01T13:27:24.786215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "trainX = np.load(\"../input/cnn-itba-2021-q2/X_train.npy\")/255\n",
    "trainY = np.load(\"../input/cnn-itba-2021-q2/y_train.npy\")\n",
    "testX = np.load(\"../input/cnn-itba-2021-q2/X_test.npy\")/255\n",
    "\n",
    "print(trainX.shape) #para ver cuantas imagenes hay (500 imágenes por cada clase. Hay 100 clases)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7806b0",
   "metadata": {
    "papermill": {
     "duration": 0.018003,
     "end_time": "2021-12-01T13:27:29.139133",
     "exception": false,
     "start_time": "2021-12-01T13:27:29.121130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dividimos train entre train y validation.\n",
    "El dataset de train se lo divide en 80% de train y 20% de validation. Esto es para poder evaluar el performance de nuestros modelos con validation antes de predecir el test y luego hacer submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84888084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T13:27:29.179021Z",
     "iopub.status.busy": "2021-12-01T13:27:29.178240Z",
     "iopub.status.idle": "2021-12-01T13:27:30.293885Z",
     "shell.execute_reply": "2021-12-01T13:27:30.293419Z",
     "shell.execute_reply.started": "2021-12-01T12:39:41.267864Z"
    },
    "papermill": {
     "duration": 1.13756,
     "end_time": "2021-12-01T13:27:30.294015",
     "exception": false,
     "start_time": "2021-12-01T13:27:29.156455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX, validX, trainY, validY = train_test_split(trainX, trainY, test_size=0.2, random_state=0)\n",
    "\n",
    "#validX = trainX[40000:,:,:,:]\n",
    "#validY = trainY[40000:,:]\n",
    "#trainX = trainX[:40000,:,:,:]\n",
    "#trainY = trainY[:40000,:]\n",
    "\n",
    "print(trainX.shape)\n",
    "print(validX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed695e0b",
   "metadata": {
    "papermill": {
     "duration": 0.017681,
     "end_time": "2021-12-01T13:27:30.329878",
     "exception": false,
     "start_time": "2021-12-01T13:27:30.312197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ploteamos una imagen para observar el contenido de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9095345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T13:27:30.370341Z",
     "iopub.status.busy": "2021-12-01T13:27:30.369546Z",
     "iopub.status.idle": "2021-12-01T13:27:30.529800Z",
     "shell.execute_reply": "2021-12-01T13:27:30.530219Z",
     "shell.execute_reply.started": "2021-12-01T12:39:41.691687Z"
    },
    "papermill": {
     "duration": 0.182962,
     "end_time": "2021-12-01T13:27:30.530363",
     "exception": false,
     "start_time": "2021-12-01T13:27:30.347401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(2,2)) #para cambiar tamaño de imagen\n",
    "plt.imshow(trainX[0]) #agarra el elemento 0. Podria poner cualquier numero\n",
    "plt.title(str(trainY[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b156e",
   "metadata": {
    "papermill": {
     "duration": 0.018383,
     "end_time": "2021-12-01T13:27:30.567195",
     "exception": false,
     "start_time": "2021-12-01T13:27:30.548812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hacemos data augmentation para \"aumentar\" nuestro dataset.\n",
    "Configuramos las capas que se encargarán de modificar, de forma aleatoria, las características de la imagen (horizontal flip, rotación, zoom y contraste) por cada iteración (epoch). Dado que estas capas se encargan de hacer el data augmentation, nuestro modelo asume que el dataset de train es mucho mayor a lo que es en realidad (40 mil imágenes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77bf325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T13:27:30.608465Z",
     "iopub.status.busy": "2021-12-01T13:27:30.607880Z",
     "iopub.status.idle": "2021-12-01T13:27:37.558710Z",
     "shell.execute_reply": "2021-12-01T13:27:37.559137Z",
     "shell.execute_reply.started": "2021-12-01T12:39:41.926156Z"
    },
    "papermill": {
     "duration": 6.97413,
     "end_time": "2021-12-01T13:27:37.559321",
     "exception": false,
     "start_time": "2021-12-01T13:27:30.585191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 13:27:35.115180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 13:27:35.214986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 13:27:35.215715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 13:27:35.216800: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-01 13:27:35.217587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 13:27:35.218271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 13:27:35.218874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 13:27:36.951591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 13:27:36.952388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 13:27:36.953009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 13:27:36.953596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom, RandomContrast\n",
    "\n",
    "dataAugmentation = Sequential([RandomFlip(\"horizontal\",input_shape=trainX.shape[1:]),\n",
    "                                RandomRotation(0.1),\n",
    "                                RandomZoom(0.1),\n",
    "                                RandomContrast(0.1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca22e7",
   "metadata": {
    "papermill": {
     "duration": 0.01862,
     "end_time": "2021-12-01T13:27:37.597028",
     "exception": false,
     "start_time": "2021-12-01T13:27:37.578408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Se diseña un modelo CNN.\n",
    "El modelo CNN implementado respeta las estructuras mencionadas en clase (por ejemplo, VGG). Se generan capas convolucionales seguidos de capas maxpooling. Se agrega una capa dropout a modo de generalizar el dataset de train. La capa flatten es utilizada para generar un 1D vector. Finalmente tenemos una capa densa (fully connected) seguido de la capa de salida con función de activación softmax para la predicción de multiclases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bac490c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T13:27:37.639520Z",
     "iopub.status.busy": "2021-12-01T13:27:37.638640Z",
     "iopub.status.idle": "2021-12-01T13:27:37.857595Z",
     "shell.execute_reply": "2021-12-01T13:27:37.856974Z",
     "shell.execute_reply.started": "2021-12-01T12:39:42.140209Z"
    },
    "papermill": {
     "duration": 0.24117,
     "end_time": "2021-12-01T13:27:37.857752",
     "exception": false,
     "start_time": "2021-12-01T13:27:37.616582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               102500    \n",
      "=================================================================\n",
      "Total params: 2,293,924\n",
      "Trainable params: 2,293,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "#Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1. It is\n",
    "#a layer that normalizes its inputs.\n",
    "\n",
    "Nclasses = 100\n",
    "model = Sequential([dataAugmentation,\n",
    "                    Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "                    MaxPooling2D(pool_size=(2, 2)),\n",
    "                    Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "                    MaxPooling2D(pool_size=(2, 2)),\n",
    "                    Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "                    MaxPooling2D(pool_size=(2, 2)),\n",
    "                    Dropout(0.4),\n",
    "                    Flatten(),\n",
    "                    Dense(1024, activation='relu'),\n",
    "                    #BatchNormalization(),\n",
    "                    Dense(Nclasses, activation='softmax')])\n",
    "\n",
    "#Use this SparseCategoricalCrossentropy loss function when there are two or more label classes. We expect labels to be provided as integers.\n",
    "#If you want to provide labels using one-hot representation, please use CategoricalCrossentropy loss.\n",
    "\n",
    "#Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n",
    "\n",
    "#Accuracy metric creates two local variables, total and count that are used to compute the frequency with which y_pred matches y_true. This\n",
    "#frequency is ultimately returned as binary accuracy: an idempotent operation that simply divides total by count.\n",
    "\n",
    "model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd66cf",
   "metadata": {
    "papermill": {
     "duration": 0.019635,
     "end_time": "2021-12-01T13:27:37.896816",
     "exception": false,
     "start_time": "2021-12-01T13:27:37.877181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Entrenamos nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48f7faa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T13:27:37.940304Z",
     "iopub.status.busy": "2021-12-01T13:27:37.938120Z",
     "iopub.status.idle": "2021-12-01T13:30:02.408015Z",
     "shell.execute_reply": "2021-12-01T13:30:02.408566Z",
     "shell.execute_reply.started": "2021-12-01T12:39:42.355768Z"
    },
    "papermill": {
     "duration": 144.492028,
     "end_time": "2021-12-01T13:30:02.408737",
     "exception": false,
     "start_time": "2021-12-01T13:27:37.916709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 13:27:39.149217: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/backend.py:4907: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n",
      "2021-12-01 13:27:40.783250: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 10s 5ms/step - loss: 3.8642 - accuracy: 0.1064\n",
      "Epoch 2/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 3.2403 - accuracy: 0.2091\n",
      "Epoch 3/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 2.9755 - accuracy: 0.2622\n",
      "Epoch 4/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 2.7977 - accuracy: 0.2952\n",
      "Epoch 5/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 2.6546 - accuracy: 0.3231\n",
      "Epoch 6/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 2.5361 - accuracy: 0.3478\n",
      "Epoch 7/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 2.4475 - accuracy: 0.3686\n",
      "Epoch 8/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 2.3669 - accuracy: 0.3826\n",
      "Epoch 9/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 2.2903 - accuracy: 0.4004\n",
      "Epoch 10/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 2.2150 - accuracy: 0.4167\n",
      "Epoch 11/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 2.1556 - accuracy: 0.4304\n",
      "Epoch 12/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 2.1103 - accuracy: 0.4363\n",
      "Epoch 13/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 2.0524 - accuracy: 0.4482\n",
      "Epoch 14/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 2.0066 - accuracy: 0.4588\n",
      "Epoch 15/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.9568 - accuracy: 0.4672\n",
      "Epoch 16/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.9198 - accuracy: 0.4778\n",
      "Epoch 17/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.8806 - accuracy: 0.4873\n",
      "Epoch 18/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.8478 - accuracy: 0.4951\n",
      "Epoch 19/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.8231 - accuracy: 0.5024\n",
      "Epoch 20/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.7832 - accuracy: 0.5085\n",
      "Epoch 21/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.7454 - accuracy: 0.5156\n",
      "Epoch 22/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.7298 - accuracy: 0.5230\n",
      "Epoch 23/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.7015 - accuracy: 0.5281\n",
      "Epoch 24/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.6816 - accuracy: 0.5307\n",
      "Epoch 25/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.6411 - accuracy: 0.5401\n",
      "Epoch 26/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.6367 - accuracy: 0.5416\n",
      "Epoch 27/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.6063 - accuracy: 0.5478\n",
      "Epoch 28/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.5835 - accuracy: 0.5558\n",
      "Epoch 29/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.5621 - accuracy: 0.5579\n",
      "Epoch 30/30\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 1.5370 - accuracy: 0.5695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1ca1b08350>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=30, batch_size=64, verbose=1, workers=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2e3c3f",
   "metadata": {
    "papermill": {
     "duration": 0.478999,
     "end_time": "2021-12-01T13:30:03.374128",
     "exception": false,
     "start_time": "2021-12-01T13:30:02.895129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Evalueamos nuestro modelo con validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c4d1a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T13:30:04.340270Z",
     "iopub.status.busy": "2021-12-01T13:30:04.339242Z",
     "iopub.status.idle": "2021-12-01T13:30:06.015648Z",
     "shell.execute_reply": "2021-12-01T13:30:06.014852Z",
     "shell.execute_reply.started": "2021-12-01T12:41:20.517043Z"
    },
    "papermill": {
     "duration": 2.160694,
     "end_time": "2021-12-01T13:30:06.015772",
     "exception": false,
     "start_time": "2021-12-01T13:30:03.855078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 2.4439 - accuracy: 0.4193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.443889617919922, 0.41929998993873596]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validX, validY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59ded2e",
   "metadata": {
    "papermill": {
     "duration": 0.484561,
     "end_time": "2021-12-01T13:30:06.984210",
     "exception": false,
     "start_time": "2021-12-01T13:30:06.499649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Se hace transfer learning\n",
    "Para implementar tranfer learning, se utilizan los pesos preentrenados de Imagenet. Se utilizará una estructura resnet de 50 capas que contendrá dichos pesos. Cabe mencionar que el modelo imagenet ha sido entrenado por imágenes de una resolución de 256x256 píxeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4804eefd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T13:30:07.961879Z",
     "iopub.status.busy": "2021-12-01T13:30:07.961346Z",
     "iopub.status.idle": "2021-12-01T13:30:09.716633Z",
     "shell.execute_reply": "2021-12-01T13:30:09.717045Z",
     "shell.execute_reply.started": "2021-12-01T12:41:21.877009Z"
    },
    "papermill": {
     "duration": 2.252085,
     "end_time": "2021-12-01T13:30:09.717245",
     "exception": false,
     "start_time": "2021-12-01T13:30:07.465160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 0s 0us/step\n",
      "94781440/94765736 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "#include_top: whether to include the fully-connected layer at the top of the network.\n",
    "\n",
    "#weights: one of None (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded.\n",
    "\n",
    "#trainable: Boolean, whether the layer's variables (weights) should be trainable (updated).\n",
    "\n",
    "#La red arranca preentrenada.\n",
    "modelResnet = ResNet50(include_top=False, weights='imagenet', input_shape=(256, 256, 3), classes=100)\n",
    "for layer in modelResnet.layers:\n",
    "    if not isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = False\n",
    "#for layer in modelResnet.layers:\n",
    "#    layer.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1fbd87a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T13:30:10.708747Z",
     "iopub.status.busy": "2021-12-01T13:30:10.707852Z",
     "iopub.status.idle": "2021-12-01T13:30:11.110291Z",
     "shell.execute_reply": "2021-12-01T13:30:11.109683Z",
     "shell.execute_reply.started": "2021-12-01T12:41:23.318825Z"
    },
    "papermill": {
     "duration": 0.902108,
     "end_time": "2021-12-01T13:30:11.110423",
     "exception": false,
     "start_time": "2021-12-01T13:30:10.208315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Preprocesses a tensor or Numpy array encoding a batch of images. The images are converted from RGB to BGR, \n",
    "#then each color channel is zero-centered with respect to the ImageNet dataset, without scaling.\n",
    "trainX = preprocess_input(trainX)\n",
    "validX = preprocess_input(validX)\n",
    "testX = preprocess_input(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4eab6",
   "metadata": {
    "papermill": {
     "duration": 0.492415,
     "end_time": "2021-12-01T13:30:12.105432",
     "exception": false,
     "start_time": "2021-12-01T13:30:11.613017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Se agregan capas al final para adaptar el modelo preentrenado a nuestro problema (ya que hay pesos que no son entrenables). Como primera capa tenemos el data augmentation explicado anteriormente. Luego se usan capas upsampling (cada una duplica el tamaño) para que la resolución para la cual Imagenet fue entrenado (256x256) coincida con la resolución utilizada en CIFAR-100 (32x32). Luego se agrega el modelo preentrenado (resnet50). Se agrega una capa dropout por lo mencionado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f953ee56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T13:30:13.338773Z",
     "iopub.status.busy": "2021-12-01T13:30:13.337352Z",
     "iopub.status.idle": "2021-12-01T13:30:13.954656Z",
     "shell.execute_reply": "2021-12-01T13:30:13.955049Z",
     "shell.execute_reply.started": "2021-12-01T12:41:23.747064Z"
    },
    "papermill": {
     "duration": 1.19312,
     "end_time": "2021-12-01T13:30:13.955239",
     "exception": false,
     "start_time": "2021-12-01T13:30:12.762119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 8, 8, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 24,138,980\n",
      "Trainable params: 603,876\n",
      "Non-trainable params: 23,535,104\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Activation, GlobalAveragePooling2D, UpSampling2D\n",
    "\n",
    "#GlobalAveragePooling2D: Downsamples the input along its spatial dimensions (height and width) by taking the average value over an input\n",
    "#window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension.\n",
    "\n",
    "model_ = Sequential([dataAugmentation,\n",
    "                    UpSampling2D(),\n",
    "                    UpSampling2D(),\n",
    "                    UpSampling2D(),\n",
    "                    modelResnet, #Acá está el modelo preentrenado.\n",
    "                    GlobalAveragePooling2D(),\n",
    "                    Dense(256, activation='relu'),\n",
    "                    Dropout(0.4),\n",
    "                    BatchNormalization(),\n",
    "                    Dense(Nclasses, activation='softmax')])\n",
    "\n",
    "model_.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model_.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0768a65",
   "metadata": {
    "papermill": {
     "duration": 0.490023,
     "end_time": "2021-12-01T13:30:14.930713",
     "exception": false,
     "start_time": "2021-12-01T13:30:14.440690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Entrenamos el modelo preentrenado con el dataset de nuestro problema. Cabe mencionar que con menos epochs, se ha logrado un accuracy mucho mayor que con el modelo no preentrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c396bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T13:30:15.946471Z",
     "iopub.status.busy": "2021-12-01T13:30:15.945549Z",
     "iopub.status.idle": "2021-12-01T14:13:43.079421Z",
     "shell.execute_reply": "2021-12-01T14:13:43.078708Z",
     "shell.execute_reply.started": "2021-12-01T12:41:24.320554Z"
    },
    "papermill": {
     "duration": 2607.628089,
     "end_time": "2021-12-01T14:13:43.079554",
     "exception": false,
     "start_time": "2021-12-01T13:30:15.451465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "625/625 [==============================] - 177s 276ms/step - loss: 3.4474 - accuracy: 0.1921\n",
      "Epoch 2/15\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 2.2837 - accuracy: 0.3982\n",
      "Epoch 3/15\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 1.8505 - accuracy: 0.4926\n",
      "Epoch 4/15\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 1.6277 - accuracy: 0.5460\n",
      "Epoch 5/15\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 1.4923 - accuracy: 0.5792\n",
      "Epoch 6/15\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 1.4116 - accuracy: 0.5992\n",
      "Epoch 7/15\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 1.3347 - accuracy: 0.6201\n",
      "Epoch 8/15\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 1.2718 - accuracy: 0.6371\n",
      "Epoch 9/15\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 1.2193 - accuracy: 0.6487\n",
      "Epoch 10/15\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 1.1818 - accuracy: 0.6577\n",
      "Epoch 11/15\n",
      "625/625 [==============================] - 172s 276ms/step - loss: 1.1445 - accuracy: 0.6666\n",
      "Epoch 12/15\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 1.1139 - accuracy: 0.6753\n",
      "Epoch 13/15\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 1.0832 - accuracy: 0.6823\n",
      "Epoch 14/15\n",
      "625/625 [==============================] - 173s 277ms/step - loss: 1.0631 - accuracy: 0.6890\n",
      "Epoch 15/15\n",
      "625/625 [==============================] - 173s 277ms/step - loss: 1.0295 - accuracy: 0.6977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1c2c10de10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.fit(trainX, trainY, epochs=15, batch_size=64, verbose=1, workers=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479ec921",
   "metadata": {
    "papermill": {
     "duration": 2.920242,
     "end_time": "2021-12-01T14:13:48.968728",
     "exception": false,
     "start_time": "2021-12-01T14:13:46.048486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Evaluemos nuestro modelo preentrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d51818bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T14:13:55.037621Z",
     "iopub.status.busy": "2021-12-01T14:13:55.036717Z",
     "iopub.status.idle": "2021-12-01T14:14:40.063915Z",
     "shell.execute_reply": "2021-12-01T14:14:40.064642Z",
     "shell.execute_reply.started": "2021-12-01T13:24:39.571128Z"
    },
    "papermill": {
     "duration": 47.947589,
     "end_time": "2021-12-01T14:14:40.064852",
     "exception": false,
     "start_time": "2021-12-01T14:13:52.117263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 22s 66ms/step - loss: 0.8673 - accuracy: 0.7444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8672987222671509, 0.7444000244140625]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.evaluate(validX, validY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34027bb4",
   "metadata": {
    "papermill": {
     "duration": 3.223466,
     "end_time": "2021-12-01T14:14:46.332400",
     "exception": false,
     "start_time": "2021-12-01T14:14:43.108934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Predecimos el test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47f4aa2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T14:14:52.889524Z",
     "iopub.status.busy": "2021-12-01T14:14:52.888591Z",
     "iopub.status.idle": "2021-12-01T14:15:12.498046Z",
     "shell.execute_reply": "2021-12-01T14:15:12.497539Z",
     "shell.execute_reply.started": "2021-12-01T13:25:21.647461Z"
    },
    "papermill": {
     "duration": 22.593827,
     "end_time": "2021-12-01T14:15:12.498198",
     "exception": false,
     "start_time": "2021-12-01T14:14:49.904371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testPred = model_.predict(testX)\n",
    "testPred = testPred.argmax(axis=1) #argmax: Returns the indices of the maximum values along an axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871bb40",
   "metadata": {
    "papermill": {
     "duration": 3.12567,
     "end_time": "2021-12-01T14:15:18.721840",
     "exception": false,
     "start_time": "2021-12-01T14:15:15.596170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Preparamos submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c11709e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T14:15:25.231653Z",
     "iopub.status.busy": "2021-12-01T14:15:25.229250Z",
     "iopub.status.idle": "2021-12-01T14:15:25.239759Z",
     "shell.execute_reply": "2021-12-01T14:15:25.240204Z",
     "shell.execute_reply.started": "2021-12-01T13:25:43.208259Z"
    },
    "papermill": {
     "duration": 2.974531,
     "end_time": "2021-12-01T14:15:25.240354",
     "exception": false,
     "start_time": "2021-12-01T14:15:22.265823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "Id       \n",
       "0      68\n",
       "1      33\n",
       "2      55\n",
       "3      51\n",
       "4      71"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=testPred, columns=[\"label\"])\n",
    "df.index.name=\"Id\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05afdd20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T14:15:31.501457Z",
     "iopub.status.busy": "2021-12-01T14:15:31.500600Z",
     "iopub.status.idle": "2021-12-01T14:15:31.525226Z",
     "shell.execute_reply": "2021-12-01T14:15:31.525645Z",
     "shell.execute_reply.started": "2021-12-01T13:25:43.229320Z"
    },
    "papermill": {
     "duration": 3.312319,
     "end_time": "2021-12-01T14:15:31.525791",
     "exception": false,
     "start_time": "2021-12-01T14:15:28.213472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2900.24387,
   "end_time": "2021-12-01T14:15:37.549976",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-01T13:27:17.306106",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
